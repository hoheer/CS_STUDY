# CS_STUDY

# 1. 운영체제 
 - 프로세스와 스레드의 차이
  프로그램: 어떤 작업을 위해 실행할 수 있는 파일
  프로세스: 연속적으로 실행되고 있는 컴퓨터 프로그램
  프로세서: 내부에서 수행하는 하드웨어의 유닛단위(서 랑 스 랑 구별 잘할것)
   프로세스의 상태 
    -1. 생성: 프로세스가 생성되는 중
    -2. 실행: 프로세스가 CPU를 점유하여 명령어들이 실행되고 있는 중
    -3. 준비: 실행되진 않지만 언제든 사용가능하도록 CPU 할당을 대기하고 있는 단계
    -4. 대기: 입출력 완료 등 특정 시그널을 기다리고 있는 상태 
    -5. 종료: 프로세스 실행이 종료됨
    
   스레드: 프로세스가 실행되는 여러 흐름의 단위, 프로세스의 특정한 수행 경로
     - STACK만 따로 할당 받고 코드, 데이터. 힙 영역은 모든 스레드가 공유한다. 스택만을 독립적으로 가지는 것은 스택이 호출시 전달되는 인자, 돌아갈 주소값, 함수 내 지역 변수등을 저장되기 위해 사용되는 메모리 공간이기에 독립적인 함수호출이 가능하다는 것이고 이는 독립적인 실행흐름을 추가하고자 하는 스레드의 목적의 최소한의 요구사항이기도 하다. 

사용자 수준 스레드의 장점
 - 이식성이 높다: 커널에 독립적으로 스케쥴링이 가능하여 모든 운영체제에 적용이 가능하다. 
 - 오버헤드가 적다: 스케쥴링이나 동기화를 위해 커널 호출을 하지 않기에 커널 영역으로 전환하는 오버헤드가 줄어든다. 
 - 유연한 스케쥴링의 가능: 커널이 아닌 스레드 라이브러리에서 스레드 스케줄링을 제어하기에 응용 프로그램에 맞게 스케줄링 할 수 있다. 

사용자 수준 스레드의 단점: 시스템의 동시성을 지원하지 않는다: 스레드가 아닌 프로세스 단위로 프로세서를 할당하여 다중 처리환경을 갖춰도 스레드 단위로 다중 처리를 하지 못한다. 동일한 프로세스의 스레드 한개가 대기상태가 되면 이 중 어떤 스레드도 실행하지 못한다.

 - 확장에 제약이 따름: 커널이 한 프로세스에 속한 여러 스레드에 프로세서를 동시에 할당할 수 없어 다중 처리 시스템에서 규모를 확장하기가 어렵다. 
 - 스레드간 보호 불가느이 스레드 간 보호에 커널의 보호방법을 사용할 수 없어 스레드 라이브러리에서 보호를 제공해야 하며 프로세스 수준에서 보호가 가능하다. 
 
 - 커널 수준 스레드와 유저 수준 스레드
  커널 수준 스레드: 커널 수준 스레드는 커널 레벨에서 생성되는 스레드이다. 운영체제 시스템 내에서 생성되어 동작하는 스레드로, 커널이 직접 관리한다. 또한 커널 수준 스레드는 사용자 수준 스레드와 1:1 관계이기 때문에 하나의 프로세스의 여러 스레드들을 병행으로 수행이 가능하다. 단 유저 모드에서 커널 모드로의 전환이 빈번하게 이뤄져 성능 저하가 발생한다. 
  
  사용자 수준 스레드: 사용자 라이브러리를 통해 생성되고 관리된다. 커널이 사용자 수준 스레드의 존재를 알지 못하기 때문에 스레드 교환에 커널이 개입하지 않는다. 커널은 스레드가 아닌 프로세스를 한 단위로 인식하고 다량의 사용자 수준 스레드가 하나의 커널 수준 스레드에 할당되기에 다대일 스레드 매핑이다. 
     
#스레드를 사용할 경우 충돌을 막기 위해 동기화를 해야하는데 이때 교착 상태에 유념해야 한다. 

 - 멀티 프로세스와 멀티 스레드 
  1. 멀티 프로세스: 하나의 응용프로그램을 여러 프로세스로 구성하여 하나의 프로세스가 하나의 작업을 맡게 하는 것. 
   -> 프로세스들은 독립된 메모리를 사용하기 때문에 문맥 교환 과정에서 캐쉬 메모리 초기화 등 무거운 작업이 진행되고 시간이 소요되며 오버헤드가 발생 
  2. 멀티 스레드: 하나의 응용프로그램을 여러개의 스레드로 구성하고 각 스레드가 하나의 작업을 맡게 하는 것, 웹 서버가 대표적인 멀티 스레드 응용프로그램 (node.js 는 싱글 스레드)
   -> 공유하는 메모리가 많아 문맥 교환 비용이 멀티 프로세스에 비해 저렴하다. 단 공유하는 메모리가 많아 하나의 쓰레드에 문제가 발생하면 전체 프로세스가 영향을 받는다. 
   
- 웹 서버에서 멀티 프로세스와 멀티 스레드 차이
 멀티 프로세스: 클라이언트가 연결 요청을 하면 서버 프로그램은 자신을 복제하여 클라이언트에 대응하게 되고 자신은 다른 클라이언트의 요청을 기다리게 됨 -> 원본 프로세스의 메모리를 모두 복제하기 때문에 자원낭비가 심하다. 

 멀티 스레드: 클라이언트 요청을 처리하는 프로세스가 아니라 스레드를 생성하여 클라이언트의 요청을 처리하도록 함. 
   
   - 멀티 프로세스 대신 멀티 스레드를 사용하는 이유 
    프로그램을 여러개 키는 것 보다 하나의 프로그램 안에서 여러 작업을 해결하는 것이 당연히 효율적이다. 문맥교환시 스레드는 스택 영역만 처리하게 되기 때문. 
    
- 경쟁 상태란 무엇인가?: 둘 이상의 입력이나 조작이 동시에 일어나 의도하지 않은 결과를 가져오는 경우. 공유자원을 접근하는 하나 또는 그 이상의 프로세스나 스레드들의 다중 접근이 올바르게 제어도지 않아 원하지 않는 결과를 불러오는 상태를 말한다. 
-      
- 교착상태란 무엇이며 교착 상태가 발생하기 위해서는 어떤 조건이 있어야 하나요? 
 교착상태(dead-lock): 서로 상대방의 작업이 끝나기 만을 기다리고 있기 때문에 결과적으로 아무것도 완료되지 못하는 상태를 말한다. 
  발생조건 4가지 모두가 충족되야 
   1. 상호배체: 한번에 한개의 프로세스만이 공유 자원을 사용할 수 있어야 한다.
   2. 점유와 대기: 최소한 하나의 자원을 점유하고 있으면서 다른 프로세스에 할당되어 사용되고 있는 자원을 추가로 점유하기 위해 대기하는 프로세스가 있어야 한다.
   3. 비선점: 다른 프로세스에 할당된 자원은 사용이 끝날 때까지 강제로 빼앗을 수 없어야 한다. 
   4. 순환 대기: 프로세스의 집합에서 n-1 은 n이 점유한 자원을 대기하여야 한다. 

 - 교착상태 해결법 -> 예방 회피, 탐지 및 회복 이렇게 크게 3가지가 존재

1. 예방 
 - 자원의 상호배제 조건 방지: 상호배제는 자원의 비 공유가 전제되어야 한다. 공유자원은 배타적 접근이 필요없어 교착 상태가 발생하지 않는다. 
 - 점유와 대기 조건 방지: 방지하기 위해선 프로세스가 작업을 수행하기 전에 필요한 자원을 모두 요청하고 획득해야 한다. 이를 최대 자원 할당 이라고 하는데 이는 자원 효율성이 낮고 기아 상태를 발생할 수 있다는 단점이 존재한다.  
 - 비선점 조건 방지: 이미 할당된 자원에 선점권이 없어야 한다. 하지만 비선점 조건을 사용한다면 어떤 프로세스든 중간에 자원을 사용할 수 있어서 기존에 사용중이던 프로세스는 작업 내용을 잃을 수 있다. 
 - 순환 대기 조건 방지: 모든 자원에 일련의 순서를 부여하고 각 프로세스가 오름차순으로만 자원을 요청할 수 있게 한다. 하지만 작업에 필요한 자원은 훨씬 오래 전부터 자원을 할당받은 상태가 되야 하므로 자원의 낭비가 있을 수 있을 수 있다. 

2. 회피
 - 프로세스 시작 중단, 은행가 알고리즘 등이 존재

동기화 문제의 해결법 
 - 유저 모드 동기화 : CRITICAL SECTION
 - 커널 모드 동기화: semaphore, mutex 
   CRITICAL SECTION: 한 프로세스 내의 스레드 사이에서만 동기화가 가능하다. 
   mutex: 여러 프로세스의 스레드 사이에서도 동기화가 가능하다. (커널 객체이기 때문이다.), 뮤텍스는 자원을 점유한 프로세스나 스레드가 잠시 소유하였다가 작업이 끝나는 반환하는 개념. 
   세마포어: 뮤텍스는 동기화 시 하나의 스레드만 실행되게 하지만 세마포어는 지정된 수만큼의 스레드가 동시에 실행되도록 동기화 하는 것이 가능함., 자원의 상태를 나타내는 일종의 변수로서 소유개념이 아님
   
   
컨텍스트 스위칭
 : 멀티 프로세스 환경에서 cpu가 하나의 프로세스를 실행하고 있는 상태에서 인터럽트 요청에 의해 다음 우선 순위의 프로세스가 실행되어야 할 때 기존의 프로세스의 상태 또는 레지스터 값을 저장하고 cpu가 다음 프로세스를 수행하도록 새로운 프로세스의 상태 또는 레지스터 값을 교체하는 작업
 
동기 비동기 블로킹 논블로킹
 - 블로킹과 논블로킹: 
 

 
# 2. 웹

7계층
1. 물리계층: 하드웨서 전송 기술로 이루어져 있다. (허브, 리피터, 케이블 등등)
2. 데이터 링크 계층: 신뢰성 있는 전송을 보장하기 위한 계층 (스위치, 브릿지, mac 주소가 여기)
3. 네트워크 계층: ip주소를 제공하는 계층. (라우터, ip공유기 등등) 전송단위가 패킷임
4. 전송 계층: 양 끝단 사용자들이 데이터를 주고 받게 하는 계층(tcp, upd), 전송 단위가 세그먼트  
5. 세션 계층: 여기부터 데이터를 만들어내는 계층, 양 끝단의 응용프로세스가 통신을 관리하기 위한 방법을 제공. 이 계층은 tcp/ip 세션을 만들고 없애는 책임을 진다. (소켓)
6. 표현 계층: 코드간의 번역을 담당하여 사용자 시스템에서 데이터의 형식상 차이를 다루는 부담을 응용계층으로부터 덜어준다. mime 인코딩이나 암호화 등의 동작이 이 계층에서 이루어짐. 압축이나 인코딩 등이 여기에서 다루어진다.
7. 응용계층: 응용프로세스와 직접관계하여 일반적인 응용서비스를 수행한다. 우리가 사용하는 사용자 인터페이스를 제공하는 프로그램이 여기속함. 우리가 잘 알고 있느 http, ftp 등의 프로토콜이 응용 계층에 속함(dns, http, ftp, dhcp)
 
 dhcp, arp 
 
 dhcp: 호스트의 tcp/ip 설정을 클라이언트에 자동으로 제공하는 프로토콜임. dhcp 서버에서 사용자 자신의 ip주소, 가장 가까운 라우터의 ip주소, 가장 가까운 dns 서버의 ip주소를 받는다. 
 arp: 가장 가까운 라우터의 mac주소를 알아낸다. 
dhcp 와 arp 를 사용하여 외부 통신 준비를 마친 후에 dns 쿼리를 dns서버에 전송하고 웹 서버의 주소 ip를 받아온다. 이후 http request를 위해 tcp소켓을 개방하고 연결한다.
이 과정에서 3 hand shaking을 통해 tcp를 연결하는 것이다. 

웹 렌더링

1. dom. cssom 생성: 서버로부터 받은 html, css를 다운받는다. 이들은 단순한 텍스트이므로 연산과 관리가 유용하도록 오브젝트 모델로 만들게 된다. (dom tree, cssom)
2. render tree: 이 두 트리를 활용하여 렌더 트리를 생성하게 된다. 순수하게 요소들의 구조와 텍스트만 존재하는 트리들과 달리 렌더 트리에는 스타일 정보가 설정되어 있으며 실제 화면에 표현되는 노드들로만 구성된다. 
3. 레이아웃 단계: 브라우저의 뷰포트 내에서 각 노드들의 정확한 위치와 크기를 계산한다. 풀어서 얘기하자면 생성된 렌더 트리 노드들이 가지고 있는 스타일과 속성에 따라서 브라우저 화면의 어느위치에 어느 크기로 출력될지 계산하는 단계하고 할 수 있다. 
4. 패인트: 레이아웃 단계 종료 후 이제 요소들을 실제 화면에 그리게 된다. 이미 요소들의 크기와 위치가 계산된 렌더 트리를 활용해 실제 픽셀값을 채워넣게 되는 단계

렌더링 최적화 - reflow, repaint 최소화
 reflow: 레이아웃 과정이 끝난 후에 액션이나 이벤트에 따라 html요소의 크기나 위치 등 레이아웃 수치를 수정하면 그에 영향을 받는 자식, 부모 노드들을 포함하여 레이아웃 과정을 다시 수행하게 된다. 
 repaint: 페인트를 또 하는 단계 
 
 즉 사용하지 않는 노드에는 visability: invisible보다 display: none을 사용한다. 인비지블은 레이아웃 공간을 차지하여 리플로우 대상이 되지만 논 디스플레이는 아예 렌더 트리에서 제외되기 때문
 또한 리페인트, 리플로우가 발생하는 css속성을 가급적 피해야 한다. 프레
tcp 헤더
 -> 160비트의 크기임. 각 필드 비트를 0과 1로 표현하여 전송하고자 하는 세그먼트의 정보를 나타낸다. 기본이 20바이트고 최대 60바이트 까지 커질 수 있다. 
tcp 연결과정. 
1. 사용자가 네이버 를 입력한다. 
2. 지정된  dns 서버로 해당 dns쿼리를 송신한다. 
3. 로컬 네임서버는 root 네임 서버에 www.naver.com 을 질의하고 
4. root 네임서버는 .com 네임서버의 ip 주소를 알려준다.  
5. 로컬 네임서버는 루트에게 받은  ip주소로 다시 .com 네임서버에 질의한다. 
6. .com 네임서버는 구글의 네임서버 ip를 전달해준다. 
7. 로컬네임서버는 받은 구글 네임서버에 쿼리를 질의한다.
8. 구글 네임서버는 구글 닷 컴 에대한 ip주소를 응답해준다. 그리고 ttl시간동안 자신의 캐쉬에 ip를 저장해준다. 
9. 로컬은 받은 ip주소를 클라이언트로 응답해준다. 
10. 클라이언트는 응답받은 ip정보로 패킷을 생성하기 시작하는데 맨 먼저 애플리케이션 계층에서 전송할 데이터를 생성한다.   그리고 시스템 콜을 호출하여 데이티를 아래 계층으로 전송한다. 
11. 그 후 각 계층을 지나며 각자 자기 계층의 헤더를 점점 더 덧 붙인다. 
12. Write 시스템 콜을 호출하면 유저 영역의 데이터가 커널 메모리로 복사되고, send socket buffer의 뒷부분에 추가된다. 순서대로 전송하기 위해서다. 그림에서 옅은 회식 상자가 이미 socket buffer에 존재하는 데이터를 의미한다. 이 다음으로 TCP를 호출한다.
13.


# 3. 메모리

cpu와 가까운(빠른 메모리) 순서 
레지스터 -> cpu 캐시 메모리 -> 메인 메모리 -> 보조기억장치 (하드) -> 외부 기억장치 
-> cpu로 부터 멀어질수록 데이터를 많이 저장가능하지만 용량이 커지고 접근속도는 느려진다. 

메모리 구조 
: 크게 5개의 영역으로 분류됨 
낮은 주소부터 
1. code 영역: 사용자가 작성한 코드가 저장되는 영역이다. 실행할 프로그램의 코드가 저장됨, 프로그램이 끝날때까지 메모리에 계속 남게되는 영역이기도 함(rom : 읽기 전용)
2. data 영역: 프로그램의 전역변수와 static 변수 등이 저장되어 있는 영역, 프로그램 실행 시 이 두 변수는 메인 함수가 호출되기 전에 데이터 영역에 할당된다. 얘도 끝까지 메모리에 남음
 또한 bss, data 2개의 세부 영역으로 또 나뉜다. 
   2-1. data 영역: 초기화가 이루어진 변수들이 저장됨. 프로그램 실행 중 자유롭게 접근해서 수정과 변경이 가능함. 사실 데이터 영역은 rom 영역에 저장되는데 전역변수와 스태틱 변수를 롬에 저장하면 계속 초기값에서 바뀔 수 없으니 데이터 영역을 램에 복사해둔다고 함 
   2-2 bss
   
3. heap 영역: 프로그램이 실행되는 동안 동적으로 사용할 데이터가 저장되는 영역. 사용자가 직접 관리하는 영역. 메모리의 낮은 주소부터 높은 주소로 할당된다. (커짐) 런타임 시 힙 영역의 크기가 결정
4. stack 영역: 함수 호출 시 생성되는 지역변수와 매개변수가 저장되는 영역. 함수 호출 시 할당되며 실행이 끝나면 메모리에서 해제된다. 높은주소 부터 낮은 주소로 할당된다. 컴파일 시 할당될 영역의 크기가 정해진다. 

+ 스택과 힙은 같은 공간을 사용한다. 그래서 둘중 하나가 커지면 나머지는 점점 작은 영역만 사용가능해짐 


페이징과 세그멘테이션 

 - 페이징: 가상 메모리는 페이지라 불리는 고정 크기의 블록으로 나누어지고 물리메모리는 프레임이라 불리는 페이지와 같은 크기의 블록들로 나누어진다. 사용자는 하나의 주소를 지정하고 하드웨어에 의해 페이지 번호와 변위로 분할된다. 페이지 테이블에는 각 페이지 번호와 그에 해당하는 프레임의 시작 물리주소를 저장해두는데 할당은 항상 프레임의 정수 배로 할당되는데 이 때 프로세스가 페이지 경계와 일치 않는 크기의 메모리를 요구하게 되면 마지막 페이지 프레임은 전부 사용되지 않는 문제가 발생(내부 단편화) 

- 세그멘테이션: 페이징 처럼 논리 메모리와 물리메모리를 같은 크기의 블록이 아닌 서로 다른 크기의 논리적 단위인 세그먼트로 분할. 사용자가 2개의 주소를 지정(세그먼트 번호와 변위) 세그먼트 테이블에는 각 세그먼트의 기준(시작 물리주소) 와 한계 (세그먼트 길이)를 저장. 서로 다른 크기의 세그먼트들이 메모리에 적재되고 제거되는 일이 반복되다 보면 자유 공간들이 많은 수의 작은 조각들로 나누어져 못 쓰게 될 수도있다. (외부 단편화)

외부 단편화를 없애는 방법으로 연속 메모리 할당 방식이 사용된다. 크게 3가지 방법으로 나뉜다.
1. 최소 적합: 메모리를 순차탐색하여 제일 먼저 발견한 적절하게 들어갈 수 있는 곳을 찾아 프로세스를 적재 -> 최고로 속도가 빠름
2. 최적 적합: 메모리를 탐색해 제일 적절하게 들어갈 수 있는 곳을 찾아 프로세스를 적재 -> 메모리 이용률 측면에서 최고, 최대한 빈 구멍을 안만드는 방식으로 운영됨 
3. 최악 적합: 메모리를 탐색해 프로세스의 크기와 제일 안 맞는 공간에 프로세스를 넣는 방식

메모리 관리 방법 중 페이지 교체 알고리즘

1. fifo 메모리에 가장 먼저 올라온 페이지를 먼저 내보낸다. 하지만 프레임의 수가 적을수록 패아자 결함이 더 발생함. 계속 교체를 해야하기 때문.
2. opt 알고리즘: 가장 사용하지 않을 페이지를 가장 우선적으로 내려 보내는 알고리즘인데 사실상 미래를 알 수 없어서 쓰기가 힘들다.
3. lru 알고리즘: 최근에 사용하지 않은 페이지를 가장 먼저 내려보내는 알고리즘: 과거만 보고 판단하기에 실질적으로 사용가능한 알고리즘. 
